# Data Augmentation

Data augmentation is a widely used technique in machine learning and computer vision to enhance a dataset by applying various transformations to the existing data. These transformations, such as rotations, flips, scaling, cropping, and color adjustments, create diverse variations of the original data. We applied the following techniques:

- Contrast Adjustment
-  Saturation Adjustment
-  Add Gaussian Blur to background
-  Rotation
-  Flipping
-  Scaling
-  Random Cropping

The goal is to improve the model's ability to generalize by ensuring it performs well when encountering spacecrafts of different shapes, sizes, and conditions. 

# Background Generation

Stable Diffusion is a cutting-edge deep learning model designed for generating high-quality, photorealistic images from text prompts. In our study, Stable Diffusion was used to generate diverse backgrounds for data augmentation. Guided by the variety of backgrounds discussed in, we employed 8 prompts to produce corresponding backgrounds. To ensure no overlap between training, validation, and test sets, the generated backgrounds were split into 80-10-10 (training:1960-validation:245-testing:245) proportions.

# Image Generation

Blender is a free and open-source 3D creation software widely used for modeling, animation, rendering, simulation, and video editing. For our project, we utilized 15 spacecraft models in the training dataset, 5 in the validation dataset, and 5 in the test dataset, and their names are mentioned in Appendix \ref{appendix: list}. These models, for example Figure \ref{gen_img}, were used to generate images with random poses, lighting, and sizes on blank backgrounds. Segmentation masks were generated for these images to facilitate future combinations of spacecraft with diverse backgrounds.

# Pipeline

The pipeline begins with the preparation of the dataset by dividing 15 spacecraft models into the training set, 5 into the validation set, and 5 into the test set, ensuring no overlap.  To evaluate algorithm perforation on segmenting spacecraft of various shapes and sizes in real-time, even on unseen data against diverse and unfamiliar backgrounds, for better understanding of generalizations during deployment.



Finally, these spacecraft images are randomly combined with backgrounds generated by Stable Diffusion XL to create a comprehensive new training dataset, resulting in a total of 31,000 training images, 5,701 validation images and 5,701 testing images, as shown in Figure \ref{data_slit}.